{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilización del Patron Pipe&amp;Filter \n",
    "### Tratamiento de lenguaje natural\n",
    "\n",
    "## Introducción\n",
    "Cuando se va a  hacer análisis de texto en lenguaje natural, antes de hacer los análisis mas complejos, se debe depurar el texto de palabras \"vacias\" desde el punto de vista analítico y luego hacer los cálculos necesarios.\n",
    "\n",
    "Este ejemplo presenta un caso de estudio básico para identificar las palabras mas importantes de un texto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (3.3)\n",
      "Requirement already satisfied: six in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from nltk) (1.11.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install pandas\n",
    "#!pip install numpy\n",
    "#!pip install scipy\n",
    "#!pip install sklearn\n",
    "#!pip install matploplib\n",
    "!pip install nltk #Libreria para lenguaje natural\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar las librerias necesarias en Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import codecs\n",
    "import re\n",
    "import copy\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descarga las palabras \"vacias\" del Inglés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "esw=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define la expresion regular para identificar palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pattern=re.compile(\"\\w+$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokeniza el texto\n",
    "Obtiene las palabras del texto dado, las convierte a minúsculas y elimina las palabfras vacias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_counter(text):\n",
    "    tokens=WordPunctTokenizer().tokenize(PorterStemmer().stem(text))\n",
    "    tokens=list(map(lambda x: x.lower(),tokens))\n",
    "    tokens = [token for token in tokens if re.match(word_pattern,token) and token not in esw]\n",
    "    return collections.Counter(tokens), len(tokens)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcula la ferecuencia absoluta y relativa de cada palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(counter,size):\n",
    "    abs_freq=np.array([el[1] for el in counter])\n",
    "    rel_freq=abs_freq/size\n",
    "    index=[el[0] for el in counter]\n",
    "    df = pd.DataFrame(data=np.array([abs_freq,rel_freq]).T,index=index, columns=[\"Frecuencia Absoluta\", \"Frecuencia Relativa\"])\n",
    "    df.index.name=\"Palabras mas comunes\"\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análiis del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frecuencia Absoluta</th>\n",
       "      <th>Frecuencia Relativa</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Palabras mas comunes</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <td>462.0</td>\n",
       "      <td>0.037727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alice</th>\n",
       "      <td>398.0</td>\n",
       "      <td>0.032500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>little</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.010452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>104.0</td>\n",
       "      <td>0.008493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>88.0</td>\n",
       "      <td>0.007186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>85.0</td>\n",
       "      <td>0.006941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>83.0</td>\n",
       "      <td>0.006778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>went</th>\n",
       "      <td>83.0</td>\n",
       "      <td>0.006778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>could</th>\n",
       "      <td>77.0</td>\n",
       "      <td>0.006288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>queen</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0.006124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Frecuencia Absoluta  Frecuencia Relativa\n",
       "Palabras mas comunes                                          \n",
       "said                                462.0             0.037727\n",
       "alice                               398.0             0.032500\n",
       "little                              128.0             0.010452\n",
       "one                                 104.0             0.008493\n",
       "know                                 88.0             0.007186\n",
       "like                                 85.0             0.006941\n",
       "would                                83.0             0.006778\n",
       "went                                 83.0             0.006778\n",
       "could                                77.0             0.006288\n",
       "queen                                75.0             0.006124"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "je_counter, je_size=get_text_counter(jane_eyre)\n",
    "\n",
    "je_df=make_df(je_counter.most_common(10),je_size)\n",
    "\n",
    "je_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
